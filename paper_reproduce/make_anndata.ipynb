{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import scipy\n",
    "import scanpy as sc\n",
    "import anndata \n",
    "import os \n",
    "import sys\n",
    "\n",
    "path='/home/ubuntu0/scBasset'\n",
    "\n",
    "# from scbasset.utils import *\n",
    "\n",
    "# plotting functions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = path+'/data/multiome_pbmc/'\n",
    "\n",
    "h5_file = data_path + 'pbmc_granulocyte_sorted_3k_filtered_feature_bc_matrix.h5'\n",
    "bed_file = data_path + 'pbmc_granulocyte_sorted_3k_atac_peaks.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu0/miniconda3/envs/scbasset/lib/python3.7/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "peak = pd.read_csv(bed_file, sep='\\t', names=['chr','start','end'])\n",
    "ad = sc.read_10x_h5(h5_file, gex_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2714 × 193208\n",
       "    var: 'gene_ids', 'feature_types', 'genome'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu0/miniconda3/envs/scbasset/lib/python3.7/site-packages/ipykernel_launcher.py:3: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu0/miniconda3/envs/scbasset/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:140: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['n_genes'] = number\n"
     ]
    }
   ],
   "source": [
    "ad_rna = ad[:, ad.var['feature_types']=='Gene Expression']\n",
    "ad_atac = ad[:, ad.var['feature_types']=='Peaks']\n",
    "ad_atac.var['chr'] = peak['chr'].values\n",
    "ad_atac.var['start'] = peak['start'].values\n",
    "ad_atac.var['end'] = peak['end'].values\n",
    "\n",
    "# basic stats\n",
    "sc.pp.filter_cells(ad_rna, min_genes=0)\n",
    "sc.pp.filter_genes(ad_rna, min_cells=0)\n",
    "sc.pp.filter_cells(ad_atac, min_genes=0)\n",
    "sc.pp.filter_genes(ad_atac, min_cells=0)\n",
    "\n",
    "# a gene need to be expressed in 5% cells\n",
    "# a peak need to be accessible in 5% cells\n",
    "thres = int(ad.shape[0]*0.05)\n",
    "ad_rna = ad_rna[:, ad_rna.var['n_cells']>thres]\n",
    "ad_atac = ad_atac[:, ad_atac.var['n_cells']>thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(View of AnnData object with n_obs × n_vars = 2714 × 8652\n",
       "     obs: 'n_genes'\n",
       "     var: 'gene_ids', 'feature_types', 'genome', 'n_cells',\n",
       " View of AnnData object with n_obs × n_vars = 2714 × 27157\n",
       "     obs: 'n_genes'\n",
       "     var: 'gene_ids', 'feature_types', 'genome', 'chr', 'start', 'end', 'n_cells')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_rna,ad_atac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ad_rna.write('rna_ad.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu0/miniconda3/envs/scbasset/lib/python3.7/site-packages/anndata/_core/anndata.py:1235: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/home/ubuntu0/miniconda3/envs/scbasset/lib/python3.7/site-packages/anndata/_core/anndata.py:1235: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    }
   ],
   "source": [
    "chrs = ['chr'+str(i) for i in range(1,23)] + ['chrX', 'chrY']\n",
    "print(chrs)\n",
    "ad_atac = ad_atac[:, ad_atac.var['chr'].isin(chrs)]\n",
    "ad_atac.write('atac_ad.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 2714 × 27150\n",
       "     obs: 'n_genes'\n",
       "     var: 'gene_ids', 'feature_types', 'genome', 'chr', 'start', 'end', 'n_cells',\n",
       " AnnData object with n_obs × n_vars = 2714 × 8652\n",
       "     obs: 'n_genes'\n",
       "     var: 'gene_ids', 'feature_types', 'genome', 'n_cells')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anndata as ad\n",
    "ad_atac2=ad.read_h5ad(path+'/atac_ad.h5ad')\n",
    "ad_rna2=ad.read_h5ad(path+ '/rna_ad.h5ad')\n",
    "ad_atac2, ad_rna2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atac_file=path+'/atac_ad.h5ad'\n",
    "process_file=path+'/processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_preprocess(file,process):   \n",
    "    from preprocess import main\n",
    "    main(file,'/home/ubuntu0/scBasset/hg38.fa',process)  \n",
    "\n",
    "def call_train(pth,epoch,bottle_neck,output,trained_model):\n",
    "    from train import main\n",
    "    main(pth,epoch,bottle_neck,output,trained_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ad_file='/home/ubuntu0/scBasset/atac_ad.h5ad', input_fasta='/home/ubuntu0/scBasset/hg38.fa', out_path='/home/ubuntu0/scBasset/processed')\n",
      "successful writing h5ad file.\n",
      "successful writing bed file.\n",
      "successful writing split file.\n",
      "successful writing sparse m.\n",
      "process 0 peaks takes 0.7 s\n",
      "process 1000 peaks takes 1.1 s\n",
      "process 2000 peaks takes 1.5 s\n",
      "process 3000 peaks takes 2.0 s\n",
      "process 4000 peaks takes 2.4 s\n",
      "process 5000 peaks takes 2.8 s\n",
      "process 6000 peaks takes 3.2 s\n",
      "process 7000 peaks takes 3.5 s\n",
      "process 8000 peaks takes 3.9 s\n",
      "process 9000 peaks takes 4.2 s\n",
      "process 10000 peaks takes 4.6 s\n",
      "process 11000 peaks takes 4.8 s\n",
      "process 12000 peaks takes 5.1 s\n",
      "process 13000 peaks takes 5.4 s\n",
      "process 14000 peaks takes 5.9 s\n",
      "process 15000 peaks takes 6.3 s\n",
      "process 16000 peaks takes 6.6 s\n",
      "process 17000 peaks takes 7.0 s\n",
      "process 18000 peaks takes 7.3 s\n",
      "process 19000 peaks takes 7.6 s\n",
      "process 20000 peaks takes 8.0 s\n",
      "process 21000 peaks takes 8.3 s\n",
      "process 22000 peaks takes 8.7 s\n",
      "process 23000 peaks takes 9.0 s\n",
      "process 24000 peaks takes 9.3 s\n",
      "process 25000 peaks takes 9.7 s\n",
      "process 26000 peaks takes 10.0 s\n",
      "process 0 peaks takes 0.5 s\n",
      "process 1000 peaks takes 0.8 s\n",
      "process 2000 peaks takes 1.0 s\n",
      "process 3000 peaks takes 1.3 s\n",
      "process 4000 peaks takes 1.5 s\n",
      "process 5000 peaks takes 1.7 s\n",
      "process 6000 peaks takes 2.0 s\n",
      "process 7000 peaks takes 2.2 s\n",
      "process 8000 peaks takes 2.4 s\n",
      "process 9000 peaks takes 2.7 s\n",
      "process 10000 peaks takes 2.9 s\n",
      "process 11000 peaks takes 3.1 s\n",
      "process 12000 peaks takes 3.4 s\n",
      "process 13000 peaks takes 3.6 s\n",
      "process 14000 peaks takes 3.8 s\n",
      "process 15000 peaks takes 4.1 s\n",
      "process 16000 peaks takes 4.3 s\n",
      "process 17000 peaks takes 4.5 s\n",
      "process 18000 peaks takes 4.8 s\n",
      "process 19000 peaks takes 5.0 s\n",
      "process 20000 peaks takes 5.2 s\n",
      "process 21000 peaks takes 5.4 s\n",
      "process 22000 peaks takes 5.7 s\n",
      "process 23000 peaks takes 5.9 s\n",
      "process 0 peaks takes 0.4 s\n",
      "process 0 peaks takes 0.4 s\n"
     ]
    }
   ],
   "source": [
    "# !python bin/scbasset_preprocess.py --ad_file atac_ad.h5ad --input_fasta hg38.fa\n",
    "call_preprocess(atac_file,process_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:29:27.915267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 21:29:28.676214: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-02 21:29:29.005144: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-02 21:29:30.322312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/ubuntu0/miniconda3/envs/scbasset/lib\n",
      "2024-02-02 21:29:30.322552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/ubuntu0/miniconda3/envs/scbasset/lib\n",
      "2024-02-02 21:29:30.322562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu memory used: 0.9GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:29:32.027870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:32.094678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:32.094735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:32.100363: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 21:29:32.104272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:32.104394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:32.104416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:33.795764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:33.797946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:33.797967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-02 21:29:33.798007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-02 21:29:33.798053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5399 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1344, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1344, 4),   0           ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)   ())                                                              \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1344, 4)     0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " gelu (GELU)                    (None, 1344, 4)      0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1344, 288)    19584       ['gelu[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1344, 288)   1152        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 448, 288)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " gelu_1 (GELU)                  (None, 448, 288)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 448, 288)     414720      ['gelu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 288)    1152        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 224, 288)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_2 (GELU)                  (None, 224, 288)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 224, 323)     465120      ['gelu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 224, 323)    1292        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 112, 323)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_3 (GELU)                  (None, 112, 323)     0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 112, 363)     586245      ['gelu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 363)    1452        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 56, 363)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_4 (GELU)                  (None, 56, 363)      0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 56, 407)      738705      ['gelu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 407)     1628        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 407)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_5 (GELU)                  (None, 28, 407)      0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 456)      927960      ['gelu_5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 456)     1824        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 456)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_6 (GELU)                  (None, 14, 456)      0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 14, 512)      1167360     ['gelu_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 512)     2048        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 7, 512)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_7 (GELU)                  (None, 7, 512)       0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 256)       131072      ['gelu_7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 256)      1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " gelu_8 (GELU)                  (None, 7, 256)       0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1792)      0           ['gelu_8[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 32)        57344       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 32)       128         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 32)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " gelu_9 (GELU)                  (None, 1, 32)        0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 2714)      89562       ['gelu_9[0][0]']                 \n",
      "                                                                                                  \n",
      " switch_reverse (SwitchReverse)  (None, 1, 2714)     0           ['dense_1[0][0]',                \n",
      "                                                                  'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2714)         0           ['switch_reverse[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,609,372\n",
      "Trainable params: 4,603,522\n",
      "Non-trainable params: 5,850\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:29:38.921244: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2024-02-02 21:29:42.428329: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-02-02 21:29:42.428558: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2024-02-02 21:29:42.428836: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-02-02 21:29:46.276195: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 43s 154ms/step - loss: 0.5033 - auc: 0.5895 - auc_1: 0.2608 - val_loss: 0.4795 - val_auc: 0.6197 - val_auc_1: 0.2904\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4779 - auc: 0.6177 - auc_1: 0.2919 - val_loss: 0.4886 - val_auc: 0.6199 - val_auc_1: 0.2924\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4753 - auc: 0.6247 - auc_1: 0.3005 - val_loss: 0.4823 - val_auc: 0.6211 - val_auc_1: 0.3028\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4723 - auc: 0.6342 - auc_1: 0.3099 - val_loss: 0.4764 - val_auc: 0.6360 - val_auc_1: 0.3064\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4712 - auc: 0.6373 - auc_1: 0.3137 - val_loss: 0.4971 - val_auc: 0.6305 - val_auc_1: 0.3061\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4701 - auc: 0.6419 - auc_1: 0.3156 - val_loss: 0.5066 - val_auc: 0.6148 - val_auc_1: 0.3084\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4686 - auc: 0.6461 - auc_1: 0.3214 - val_loss: 0.4921 - val_auc: 0.6230 - val_auc_1: 0.2970\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4679 - auc: 0.6487 - auc_1: 0.3237 - val_loss: 0.4733 - val_auc: 0.6433 - val_auc_1: 0.3239\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4663 - auc: 0.6536 - auc_1: 0.3270 - val_loss: 0.4786 - val_auc: 0.6407 - val_auc_1: 0.3212\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4650 - auc: 0.6575 - auc_1: 0.3313 - val_loss: 0.4740 - val_auc: 0.6398 - val_auc_1: 0.3217\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4645 - auc: 0.6592 - auc_1: 0.3314 - val_loss: 0.4727 - val_auc: 0.6368 - val_auc_1: 0.3192\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4628 - auc: 0.6640 - auc_1: 0.3373 - val_loss: 0.4764 - val_auc: 0.6313 - val_auc_1: 0.3158\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4612 - auc: 0.6683 - auc_1: 0.3411 - val_loss: 0.4765 - val_auc: 0.6348 - val_auc_1: 0.3234\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4598 - auc: 0.6727 - auc_1: 0.3454 - val_loss: 0.4695 - val_auc: 0.6492 - val_auc_1: 0.3277\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4576 - auc: 0.6782 - auc_1: 0.3521 - val_loss: 0.4767 - val_auc: 0.6473 - val_auc_1: 0.3214\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4555 - auc: 0.6837 - auc_1: 0.3572 - val_loss: 0.4840 - val_auc: 0.6421 - val_auc_1: 0.3142\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4531 - auc: 0.6891 - auc_1: 0.3641 - val_loss: 0.4999 - val_auc: 0.5720 - val_auc_1: 0.2598\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4515 - auc: 0.6932 - auc_1: 0.3676 - val_loss: 0.4747 - val_auc: 0.6455 - val_auc_1: 0.3243\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4484 - auc: 0.6999 - auc_1: 0.3785 - val_loss: 0.4780 - val_auc: 0.6344 - val_auc_1: 0.3076\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4464 - auc: 0.7038 - auc_1: 0.3843 - val_loss: 0.4900 - val_auc: 0.6368 - val_auc_1: 0.3109\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4435 - auc: 0.7095 - auc_1: 0.3921 - val_loss: 0.4780 - val_auc: 0.6427 - val_auc_1: 0.3221\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4398 - auc: 0.7171 - auc_1: 0.4030 - val_loss: 0.4914 - val_auc: 0.6166 - val_auc_1: 0.2837\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4386 - auc: 0.7195 - auc_1: 0.4060 - val_loss: 0.4839 - val_auc: 0.6214 - val_auc_1: 0.2872\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4357 - auc: 0.7246 - auc_1: 0.4143 - val_loss: 0.4812 - val_auc: 0.6342 - val_auc_1: 0.3004\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4324 - auc: 0.7306 - auc_1: 0.4234 - val_loss: 0.4784 - val_auc: 0.6425 - val_auc_1: 0.3211\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4296 - auc: 0.7357 - auc_1: 0.4294 - val_loss: 0.4827 - val_auc: 0.6380 - val_auc_1: 0.3077\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4287 - auc: 0.7374 - auc_1: 0.4315 - val_loss: 0.4847 - val_auc: 0.6387 - val_auc_1: 0.3102\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4259 - auc: 0.7425 - auc_1: 0.4383 - val_loss: 0.4741 - val_auc: 0.6474 - val_auc_1: 0.3251\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4247 - auc: 0.7445 - auc_1: 0.4405 - val_loss: 0.4780 - val_auc: 0.6449 - val_auc_1: 0.3219\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4224 - auc: 0.7489 - auc_1: 0.4451 - val_loss: 0.4928 - val_auc: 0.6432 - val_auc_1: 0.3142\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4215 - auc: 0.7503 - auc_1: 0.4469 - val_loss: 0.4940 - val_auc: 0.6313 - val_auc_1: 0.2969\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4188 - auc: 0.7548 - auc_1: 0.4529 - val_loss: 0.4818 - val_auc: 0.6367 - val_auc_1: 0.3109\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4182 - auc: 0.7560 - auc_1: 0.4541 - val_loss: 0.4821 - val_auc: 0.6378 - val_auc_1: 0.3165\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4165 - auc: 0.7588 - auc_1: 0.4590 - val_loss: 0.4810 - val_auc: 0.6422 - val_auc_1: 0.3180\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4158 - auc: 0.7603 - auc_1: 0.4575 - val_loss: 0.4877 - val_auc: 0.6491 - val_auc_1: 0.3248\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4148 - auc: 0.7619 - auc_1: 0.4611 - val_loss: 0.4762 - val_auc: 0.6449 - val_auc_1: 0.3199\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4137 - auc: 0.7640 - auc_1: 0.4627 - val_loss: 0.4833 - val_auc: 0.6427 - val_auc_1: 0.3194\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4132 - auc: 0.7649 - auc_1: 0.4634 - val_loss: 0.4780 - val_auc: 0.6472 - val_auc_1: 0.3244\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4115 - auc: 0.7675 - auc_1: 0.4673 - val_loss: 0.4817 - val_auc: 0.6413 - val_auc_1: 0.3159\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4108 - auc: 0.7688 - auc_1: 0.4684 - val_loss: 0.4814 - val_auc: 0.6447 - val_auc_1: 0.3143\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4098 - auc: 0.7704 - auc_1: 0.4706 - val_loss: 0.4860 - val_auc: 0.6370 - val_auc_1: 0.3143\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4094 - auc: 0.7714 - auc_1: 0.4696 - val_loss: 0.4817 - val_auc: 0.6437 - val_auc_1: 0.3221\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4083 - auc: 0.7729 - auc_1: 0.4735 - val_loss: 0.4796 - val_auc: 0.6415 - val_auc_1: 0.3213\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4076 - auc: 0.7741 - auc_1: 0.4752 - val_loss: 0.4856 - val_auc: 0.6441 - val_auc_1: 0.3194\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4073 - auc: 0.7745 - auc_1: 0.4759 - val_loss: 0.4815 - val_auc: 0.6401 - val_auc_1: 0.3201\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4064 - auc: 0.7759 - auc_1: 0.4765 - val_loss: 0.4828 - val_auc: 0.6387 - val_auc_1: 0.3174\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4053 - auc: 0.7773 - auc_1: 0.4802 - val_loss: 0.4873 - val_auc: 0.6261 - val_auc_1: 0.3058\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4056 - auc: 0.7774 - auc_1: 0.4793 - val_loss: 0.4829 - val_auc: 0.6426 - val_auc_1: 0.3249\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4053 - auc: 0.7779 - auc_1: 0.4790 - val_loss: 0.4827 - val_auc: 0.6452 - val_auc_1: 0.3229\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4044 - auc: 0.7795 - auc_1: 0.4806 - val_loss: 0.4930 - val_auc: 0.6294 - val_auc_1: 0.3055\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4042 - auc: 0.7795 - auc_1: 0.4812 - val_loss: 0.4845 - val_auc: 0.6448 - val_auc_1: 0.3227\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.4035 - auc: 0.7806 - auc_1: 0.4822 - val_loss: 0.4845 - val_auc: 0.6351 - val_auc_1: 0.3142\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4033 - auc: 0.7809 - auc_1: 0.4831 - val_loss: 0.4827 - val_auc: 0.6415 - val_auc_1: 0.3191\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4035 - auc: 0.7803 - auc_1: 0.4830 - val_loss: 0.4835 - val_auc: 0.6395 - val_auc_1: 0.3237\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4023 - auc: 0.7825 - auc_1: 0.4851 - val_loss: 0.4797 - val_auc: 0.6463 - val_auc_1: 0.3228\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4020 - auc: 0.7829 - auc_1: 0.4855 - val_loss: 0.4813 - val_auc: 0.6448 - val_auc_1: 0.3269\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4016 - auc: 0.7836 - auc_1: 0.4862 - val_loss: 0.4826 - val_auc: 0.6445 - val_auc_1: 0.3266\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4011 - auc: 0.7844 - auc_1: 0.4866 - val_loss: 0.4826 - val_auc: 0.6510 - val_auc_1: 0.3345\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4014 - auc: 0.7838 - auc_1: 0.4870 - val_loss: 0.4787 - val_auc: 0.6472 - val_auc_1: 0.3309\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4001 - auc: 0.7856 - auc_1: 0.4893 - val_loss: 0.4857 - val_auc: 0.6386 - val_auc_1: 0.3201\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.4004 - auc: 0.7854 - auc_1: 0.4890 - val_loss: 0.4840 - val_auc: 0.6330 - val_auc_1: 0.3104\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3998 - auc: 0.7865 - auc_1: 0.4894 - val_loss: 0.4828 - val_auc: 0.6408 - val_auc_1: 0.3194\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3995 - auc: 0.7867 - auc_1: 0.4898 - val_loss: 0.4847 - val_auc: 0.6386 - val_auc_1: 0.3124\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3992 - auc: 0.7870 - auc_1: 0.4904 - val_loss: 0.4864 - val_auc: 0.6404 - val_auc_1: 0.3174\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3986 - auc: 0.7880 - auc_1: 0.4922 - val_loss: 0.4830 - val_auc: 0.6385 - val_auc_1: 0.3202\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3986 - auc: 0.7879 - auc_1: 0.4925 - val_loss: 0.4819 - val_auc: 0.6483 - val_auc_1: 0.3267\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3981 - auc: 0.7885 - auc_1: 0.4932 - val_loss: 0.4790 - val_auc: 0.6461 - val_auc_1: 0.3253\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3983 - auc: 0.7884 - auc_1: 0.4927 - val_loss: 0.4796 - val_auc: 0.6487 - val_auc_1: 0.3285\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3976 - auc: 0.7894 - auc_1: 0.4938 - val_loss: 0.4793 - val_auc: 0.6491 - val_auc_1: 0.3314\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3975 - auc: 0.7895 - auc_1: 0.4940 - val_loss: 0.4803 - val_auc: 0.6490 - val_auc_1: 0.3259\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3974 - auc: 0.7895 - auc_1: 0.4943 - val_loss: 0.4848 - val_auc: 0.6449 - val_auc_1: 0.3240\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3972 - auc: 0.7899 - auc_1: 0.4948 - val_loss: 0.4805 - val_auc: 0.6457 - val_auc_1: 0.3257\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3970 - auc: 0.7904 - auc_1: 0.4944 - val_loss: 0.4829 - val_auc: 0.6443 - val_auc_1: 0.3243\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3970 - auc: 0.7901 - auc_1: 0.4953 - val_loss: 0.4872 - val_auc: 0.6368 - val_auc_1: 0.3130\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3964 - auc: 0.7911 - auc_1: 0.4961 - val_loss: 0.4811 - val_auc: 0.6486 - val_auc_1: 0.3250\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 29s 147ms/step - loss: 0.3962 - auc: 0.7914 - auc_1: 0.4964 - val_loss: 0.4832 - val_auc: 0.6423 - val_auc_1: 0.3217\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3963 - auc: 0.7913 - auc_1: 0.4959 - val_loss: 0.4860 - val_auc: 0.6385 - val_auc_1: 0.3206\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3961 - auc: 0.7915 - auc_1: 0.4967 - val_loss: 0.4822 - val_auc: 0.6346 - val_auc_1: 0.3133\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3959 - auc: 0.7918 - auc_1: 0.4973 - val_loss: 0.4880 - val_auc: 0.6417 - val_auc_1: 0.3253\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3956 - auc: 0.7923 - auc_1: 0.4975 - val_loss: 0.4834 - val_auc: 0.6362 - val_auc_1: 0.3088\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 28s 145ms/step - loss: 0.3952 - auc: 0.7927 - auc_1: 0.4987 - val_loss: 0.4803 - val_auc: 0.6449 - val_auc_1: 0.3217\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3954 - auc: 0.7925 - auc_1: 0.4975 - val_loss: 0.4848 - val_auc: 0.6403 - val_auc_1: 0.3206\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 28s 145ms/step - loss: 0.3952 - auc: 0.7927 - auc_1: 0.4991 - val_loss: 0.4822 - val_auc: 0.6447 - val_auc_1: 0.3237\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 28s 146ms/step - loss: 0.3949 - auc: 0.7931 - auc_1: 0.4991 - val_loss: 0.4811 - val_auc: 0.6432 - val_auc_1: 0.3223\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3949 - auc: 0.7932 - auc_1: 0.4995 - val_loss: 0.4804 - val_auc: 0.6443 - val_auc_1: 0.3269\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3951 - auc: 0.7929 - auc_1: 0.4993 - val_loss: 0.4836 - val_auc: 0.6346 - val_auc_1: 0.3173\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3944 - auc: 0.7938 - auc_1: 0.5003 - val_loss: 0.4886 - val_auc: 0.6312 - val_auc_1: 0.3103\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3946 - auc: 0.7936 - auc_1: 0.5001 - val_loss: 0.4820 - val_auc: 0.6430 - val_auc_1: 0.3227\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3938 - auc: 0.7947 - auc_1: 0.5014 - val_loss: 0.4790 - val_auc: 0.6475 - val_auc_1: 0.3256\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3940 - auc: 0.7943 - auc_1: 0.5016 - val_loss: 0.4844 - val_auc: 0.6442 - val_auc_1: 0.3238\n",
      "Epoch 91/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3936 - auc: 0.7949 - auc_1: 0.5008 - val_loss: 0.4917 - val_auc: 0.6447 - val_auc_1: 0.3247\n",
      "Epoch 92/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3934 - auc: 0.7952 - auc_1: 0.5020 - val_loss: 0.4954 - val_auc: 0.6396 - val_auc_1: 0.3198\n",
      "Epoch 93/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3935 - auc: 0.7949 - auc_1: 0.5024 - val_loss: 0.4825 - val_auc: 0.6453 - val_auc_1: 0.3219\n",
      "Epoch 94/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3935 - auc: 0.7950 - auc_1: 0.5020 - val_loss: 0.4865 - val_auc: 0.6384 - val_auc_1: 0.3204\n",
      "Epoch 95/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3935 - auc: 0.7951 - auc_1: 0.5024 - val_loss: 0.4803 - val_auc: 0.6451 - val_auc_1: 0.3281\n",
      "Epoch 96/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3932 - auc: 0.7954 - auc_1: 0.5029 - val_loss: 0.4830 - val_auc: 0.6448 - val_auc_1: 0.3266\n",
      "Epoch 97/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3932 - auc: 0.7955 - auc_1: 0.5026 - val_loss: 0.4850 - val_auc: 0.6451 - val_auc_1: 0.3257\n",
      "Epoch 98/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3931 - auc: 0.7956 - auc_1: 0.5030 - val_loss: 0.4802 - val_auc: 0.6404 - val_auc_1: 0.3216\n",
      "Epoch 99/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3928 - auc: 0.7961 - auc_1: 0.5036 - val_loss: 0.4840 - val_auc: 0.6535 - val_auc_1: 0.3361\n",
      "Epoch 100/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3930 - auc: 0.7958 - auc_1: 0.5028 - val_loss: 0.4802 - val_auc: 0.6443 - val_auc_1: 0.3228\n",
      "Epoch 101/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3930 - auc: 0.7958 - auc_1: 0.5034 - val_loss: 0.4873 - val_auc: 0.6395 - val_auc_1: 0.3229\n",
      "Epoch 102/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3927 - auc: 0.7960 - auc_1: 0.5038 - val_loss: 0.4889 - val_auc: 0.6476 - val_auc_1: 0.3292\n",
      "Epoch 103/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3925 - auc: 0.7964 - auc_1: 0.5045 - val_loss: 0.4825 - val_auc: 0.6384 - val_auc_1: 0.3215\n",
      "Epoch 104/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3924 - auc: 0.7965 - auc_1: 0.5045 - val_loss: 0.4819 - val_auc: 0.6405 - val_auc_1: 0.3198\n",
      "Epoch 105/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3924 - auc: 0.7964 - auc_1: 0.5040 - val_loss: 0.4802 - val_auc: 0.6485 - val_auc_1: 0.3309\n",
      "Epoch 106/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3920 - auc: 0.7970 - auc_1: 0.5054 - val_loss: 0.4831 - val_auc: 0.6479 - val_auc_1: 0.3270\n",
      "Epoch 107/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3922 - auc: 0.7967 - auc_1: 0.5046 - val_loss: 0.4779 - val_auc: 0.6471 - val_auc_1: 0.3252\n",
      "Epoch 108/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3918 - auc: 0.7973 - auc_1: 0.5053 - val_loss: 0.4836 - val_auc: 0.6446 - val_auc_1: 0.3246\n",
      "Epoch 109/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3919 - auc: 0.7972 - auc_1: 0.5060 - val_loss: 0.4823 - val_auc: 0.6454 - val_auc_1: 0.3220\n",
      "Epoch 110/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3914 - auc: 0.7978 - auc_1: 0.5063 - val_loss: 0.4836 - val_auc: 0.6472 - val_auc_1: 0.3267\n",
      "Epoch 111/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3915 - auc: 0.7976 - auc_1: 0.5059 - val_loss: 0.4791 - val_auc: 0.6464 - val_auc_1: 0.3241\n",
      "Epoch 112/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3914 - auc: 0.7977 - auc_1: 0.5066 - val_loss: 0.4810 - val_auc: 0.6465 - val_auc_1: 0.3247\n",
      "Epoch 113/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3915 - auc: 0.7977 - auc_1: 0.5056 - val_loss: 0.4830 - val_auc: 0.6411 - val_auc_1: 0.3206\n",
      "Epoch 114/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3918 - auc: 0.7973 - auc_1: 0.5058 - val_loss: 0.4838 - val_auc: 0.6496 - val_auc_1: 0.3257\n",
      "Epoch 115/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3913 - auc: 0.7980 - auc_1: 0.5067 - val_loss: 0.4809 - val_auc: 0.6489 - val_auc_1: 0.3268\n",
      "Epoch 116/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3912 - auc: 0.7981 - auc_1: 0.5063 - val_loss: 0.4789 - val_auc: 0.6467 - val_auc_1: 0.3261\n",
      "Epoch 117/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3912 - auc: 0.7982 - auc_1: 0.5067 - val_loss: 0.4819 - val_auc: 0.6441 - val_auc_1: 0.3207\n",
      "Epoch 118/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3912 - auc: 0.7980 - auc_1: 0.5074 - val_loss: 0.4824 - val_auc: 0.6458 - val_auc_1: 0.3260\n",
      "Epoch 119/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3909 - auc: 0.7984 - auc_1: 0.5077 - val_loss: 0.4816 - val_auc: 0.6416 - val_auc_1: 0.3211\n",
      "Epoch 120/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3910 - auc: 0.7983 - auc_1: 0.5071 - val_loss: 0.4823 - val_auc: 0.6453 - val_auc_1: 0.3222\n",
      "Epoch 121/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3911 - auc: 0.7982 - auc_1: 0.5075 - val_loss: 0.4787 - val_auc: 0.6519 - val_auc_1: 0.3304\n",
      "Epoch 122/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3912 - auc: 0.7981 - auc_1: 0.5069 - val_loss: 0.4791 - val_auc: 0.6505 - val_auc_1: 0.3301\n",
      "Epoch 123/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3910 - auc: 0.7983 - auc_1: 0.5068 - val_loss: 0.4813 - val_auc: 0.6483 - val_auc_1: 0.3265\n",
      "Epoch 124/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3907 - auc: 0.7986 - auc_1: 0.5084 - val_loss: 0.4802 - val_auc: 0.6464 - val_auc_1: 0.3274\n",
      "Epoch 125/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3903 - auc: 0.7993 - auc_1: 0.5084 - val_loss: 0.4829 - val_auc: 0.6403 - val_auc_1: 0.3168\n",
      "Epoch 126/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3904 - auc: 0.7990 - auc_1: 0.5089 - val_loss: 0.4844 - val_auc: 0.6432 - val_auc_1: 0.3175\n",
      "Epoch 127/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3906 - auc: 0.7988 - auc_1: 0.5082 - val_loss: 0.4811 - val_auc: 0.6435 - val_auc_1: 0.3191\n",
      "Epoch 128/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3901 - auc: 0.7995 - auc_1: 0.5088 - val_loss: 0.4832 - val_auc: 0.6492 - val_auc_1: 0.3272\n",
      "Epoch 129/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3903 - auc: 0.7993 - auc_1: 0.5085 - val_loss: 0.4814 - val_auc: 0.6502 - val_auc_1: 0.3288\n",
      "Epoch 130/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3906 - auc: 0.7989 - auc_1: 0.5082 - val_loss: 0.4783 - val_auc: 0.6459 - val_auc_1: 0.3262\n",
      "Epoch 131/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3900 - auc: 0.7997 - auc_1: 0.5092 - val_loss: 0.4841 - val_auc: 0.6459 - val_auc_1: 0.3244\n",
      "Epoch 132/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3905 - auc: 0.7990 - auc_1: 0.5086 - val_loss: 0.4807 - val_auc: 0.6464 - val_auc_1: 0.3235\n",
      "Epoch 133/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3898 - auc: 0.7999 - auc_1: 0.5095 - val_loss: 0.4797 - val_auc: 0.6503 - val_auc_1: 0.3294\n",
      "Epoch 134/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3899 - auc: 0.7998 - auc_1: 0.5095 - val_loss: 0.4809 - val_auc: 0.6442 - val_auc_1: 0.3206\n",
      "Epoch 135/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3900 - auc: 0.7995 - auc_1: 0.5094 - val_loss: 0.4840 - val_auc: 0.6472 - val_auc_1: 0.3258\n",
      "Epoch 136/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3897 - auc: 0.8000 - auc_1: 0.5101 - val_loss: 0.4826 - val_auc: 0.6471 - val_auc_1: 0.3253\n",
      "Epoch 137/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3903 - auc: 0.7993 - auc_1: 0.5086 - val_loss: 0.4832 - val_auc: 0.6378 - val_auc_1: 0.3160\n",
      "Epoch 138/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3898 - auc: 0.7998 - auc_1: 0.5095 - val_loss: 0.4832 - val_auc: 0.6474 - val_auc_1: 0.3230\n",
      "Epoch 139/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3896 - auc: 0.8002 - auc_1: 0.5104 - val_loss: 0.4853 - val_auc: 0.6493 - val_auc_1: 0.3282\n",
      "Epoch 140/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3901 - auc: 0.7995 - auc_1: 0.5091 - val_loss: 0.4803 - val_auc: 0.6461 - val_auc_1: 0.3207\n",
      "Epoch 141/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3896 - auc: 0.8002 - auc_1: 0.5102 - val_loss: 0.4794 - val_auc: 0.6413 - val_auc_1: 0.3176\n",
      "Epoch 142/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3893 - auc: 0.8005 - auc_1: 0.5106 - val_loss: 0.4811 - val_auc: 0.6428 - val_auc_1: 0.3184\n",
      "Epoch 143/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3896 - auc: 0.8003 - auc_1: 0.5094 - val_loss: 0.4843 - val_auc: 0.6453 - val_auc_1: 0.3193\n",
      "Epoch 144/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3894 - auc: 0.8004 - auc_1: 0.5108 - val_loss: 0.4803 - val_auc: 0.6465 - val_auc_1: 0.3226\n",
      "Epoch 145/200\n",
      "191/191 [==============================] - 28s 145ms/step - loss: 0.3891 - auc: 0.8008 - auc_1: 0.5105 - val_loss: 0.4813 - val_auc: 0.6512 - val_auc_1: 0.3292\n",
      "Epoch 146/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3892 - auc: 0.8007 - auc_1: 0.5109 - val_loss: 0.4823 - val_auc: 0.6459 - val_auc_1: 0.3218\n",
      "Epoch 147/200\n",
      "191/191 [==============================] - 28s 144ms/step - loss: 0.3889 - auc: 0.8009 - auc_1: 0.5117 - val_loss: 0.4830 - val_auc: 0.6494 - val_auc_1: 0.3236\n",
      "Epoch 148/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3891 - auc: 0.8007 - auc_1: 0.5113 - val_loss: 0.4788 - val_auc: 0.6489 - val_auc_1: 0.3259\n",
      "Epoch 149/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3894 - auc: 0.8004 - auc_1: 0.5112 - val_loss: 0.4814 - val_auc: 0.6418 - val_auc_1: 0.3185\n",
      "Epoch 150/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3892 - auc: 0.8008 - auc_1: 0.5104 - val_loss: 0.4866 - val_auc: 0.6463 - val_auc_1: 0.3246\n",
      "Epoch 151/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3889 - auc: 0.8011 - auc_1: 0.5110 - val_loss: 0.4795 - val_auc: 0.6485 - val_auc_1: 0.3272\n",
      "Epoch 152/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3888 - auc: 0.8012 - auc_1: 0.5111 - val_loss: 0.4824 - val_auc: 0.6452 - val_auc_1: 0.3231\n",
      "Epoch 153/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3888 - auc: 0.8011 - auc_1: 0.5113 - val_loss: 0.4806 - val_auc: 0.6528 - val_auc_1: 0.3289\n",
      "Epoch 154/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3884 - auc: 0.8017 - auc_1: 0.5122 - val_loss: 0.4825 - val_auc: 0.6513 - val_auc_1: 0.3277\n",
      "Epoch 155/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3885 - auc: 0.8016 - auc_1: 0.5120 - val_loss: 0.4798 - val_auc: 0.6500 - val_auc_1: 0.3284\n",
      "Epoch 156/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3894 - auc: 0.8004 - auc_1: 0.5108 - val_loss: 0.4804 - val_auc: 0.6455 - val_auc_1: 0.3232\n",
      "Epoch 157/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3887 - auc: 0.8013 - auc_1: 0.5115 - val_loss: 0.4780 - val_auc: 0.6500 - val_auc_1: 0.3293\n",
      "Epoch 158/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3887 - auc: 0.8013 - auc_1: 0.5111 - val_loss: 0.4788 - val_auc: 0.6525 - val_auc_1: 0.3288\n",
      "Epoch 159/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3888 - auc: 0.8013 - auc_1: 0.5110 - val_loss: 0.4793 - val_auc: 0.6531 - val_auc_1: 0.3314\n",
      "Epoch 160/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3888 - auc: 0.8013 - auc_1: 0.5115 - val_loss: 0.4792 - val_auc: 0.6544 - val_auc_1: 0.3302\n",
      "Epoch 161/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3882 - auc: 0.8020 - auc_1: 0.5122 - val_loss: 0.4820 - val_auc: 0.6501 - val_auc_1: 0.3258\n",
      "Epoch 162/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3881 - auc: 0.8022 - auc_1: 0.5127 - val_loss: 0.4772 - val_auc: 0.6509 - val_auc_1: 0.3273\n",
      "Epoch 163/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3880 - auc: 0.8021 - auc_1: 0.5133 - val_loss: 0.4798 - val_auc: 0.6501 - val_auc_1: 0.3239\n",
      "Epoch 164/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3879 - auc: 0.8023 - auc_1: 0.5130 - val_loss: 0.4800 - val_auc: 0.6525 - val_auc_1: 0.3314\n",
      "Epoch 165/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3879 - auc: 0.8022 - auc_1: 0.5134 - val_loss: 0.4841 - val_auc: 0.6409 - val_auc_1: 0.3180\n",
      "Epoch 166/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3879 - auc: 0.8023 - auc_1: 0.5129 - val_loss: 0.4800 - val_auc: 0.6513 - val_auc_1: 0.3287\n",
      "Epoch 167/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3878 - auc: 0.8025 - auc_1: 0.5132 - val_loss: 0.4864 - val_auc: 0.6396 - val_auc_1: 0.3169\n",
      "Epoch 168/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3881 - auc: 0.8021 - auc_1: 0.5122 - val_loss: 0.4797 - val_auc: 0.6488 - val_auc_1: 0.3249\n",
      "Epoch 169/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3876 - auc: 0.8027 - auc_1: 0.5141 - val_loss: 0.4792 - val_auc: 0.6484 - val_auc_1: 0.3243\n",
      "Epoch 170/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3883 - auc: 0.8019 - auc_1: 0.5119 - val_loss: 0.4801 - val_auc: 0.6509 - val_auc_1: 0.3288\n",
      "Epoch 171/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3877 - auc: 0.8027 - auc_1: 0.5128 - val_loss: 0.4797 - val_auc: 0.6502 - val_auc_1: 0.3269\n",
      "Epoch 172/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3874 - auc: 0.8030 - auc_1: 0.5141 - val_loss: 0.4775 - val_auc: 0.6525 - val_auc_1: 0.3321\n",
      "Epoch 173/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3876 - auc: 0.8028 - auc_1: 0.5140 - val_loss: 0.4783 - val_auc: 0.6551 - val_auc_1: 0.3324\n",
      "Epoch 174/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3873 - auc: 0.8032 - auc_1: 0.5141 - val_loss: 0.4808 - val_auc: 0.6454 - val_auc_1: 0.3227\n",
      "Epoch 175/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3875 - auc: 0.8028 - auc_1: 0.5135 - val_loss: 0.4807 - val_auc: 0.6482 - val_auc_1: 0.3219\n",
      "Epoch 176/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3873 - auc: 0.8033 - auc_1: 0.5136 - val_loss: 0.4767 - val_auc: 0.6495 - val_auc_1: 0.3294\n",
      "Epoch 177/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3874 - auc: 0.8031 - auc_1: 0.5132 - val_loss: 0.4782 - val_auc: 0.6508 - val_auc_1: 0.3299\n",
      "Epoch 178/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3871 - auc: 0.8033 - auc_1: 0.5141 - val_loss: 0.4792 - val_auc: 0.6466 - val_auc_1: 0.3206\n",
      "Epoch 179/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3869 - auc: 0.8036 - auc_1: 0.5146 - val_loss: 0.4806 - val_auc: 0.6535 - val_auc_1: 0.3279\n",
      "Epoch 180/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3873 - auc: 0.8033 - auc_1: 0.5139 - val_loss: 0.4821 - val_auc: 0.6476 - val_auc_1: 0.3240\n",
      "Epoch 181/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3869 - auc: 0.8037 - auc_1: 0.5147 - val_loss: 0.4801 - val_auc: 0.6447 - val_auc_1: 0.3233\n",
      "Epoch 182/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3870 - auc: 0.8034 - auc_1: 0.5144 - val_loss: 0.4783 - val_auc: 0.6460 - val_auc_1: 0.3229\n",
      "Epoch 183/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3868 - auc: 0.8037 - auc_1: 0.5143 - val_loss: 0.4814 - val_auc: 0.6459 - val_auc_1: 0.3247\n",
      "Epoch 184/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3867 - auc: 0.8038 - auc_1: 0.5149 - val_loss: 0.4797 - val_auc: 0.6491 - val_auc_1: 0.3267\n",
      "Epoch 185/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3866 - auc: 0.8042 - auc_1: 0.5148 - val_loss: 0.4771 - val_auc: 0.6555 - val_auc_1: 0.3335\n",
      "Epoch 186/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3865 - auc: 0.8042 - auc_1: 0.5151 - val_loss: 0.4771 - val_auc: 0.6516 - val_auc_1: 0.3324\n",
      "Epoch 187/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3869 - auc: 0.8038 - auc_1: 0.5145 - val_loss: 0.4784 - val_auc: 0.6485 - val_auc_1: 0.3276\n",
      "Epoch 188/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3867 - auc: 0.8040 - auc_1: 0.5148 - val_loss: 0.4794 - val_auc: 0.6469 - val_auc_1: 0.3238\n",
      "Epoch 189/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3867 - auc: 0.8039 - auc_1: 0.5144 - val_loss: 0.4855 - val_auc: 0.6456 - val_auc_1: 0.3252\n",
      "Epoch 190/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3873 - auc: 0.8032 - auc_1: 0.5137 - val_loss: 0.4761 - val_auc: 0.6476 - val_auc_1: 0.3273\n",
      "Epoch 191/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3866 - auc: 0.8042 - auc_1: 0.5148 - val_loss: 0.4859 - val_auc: 0.6469 - val_auc_1: 0.3296\n",
      "Epoch 192/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3868 - auc: 0.8039 - auc_1: 0.5142 - val_loss: 0.4781 - val_auc: 0.6469 - val_auc_1: 0.3277\n",
      "Epoch 193/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3865 - auc: 0.8042 - auc_1: 0.5153 - val_loss: 0.4783 - val_auc: 0.6480 - val_auc_1: 0.3261\n",
      "Epoch 194/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3865 - auc: 0.8042 - auc_1: 0.5147 - val_loss: 0.4792 - val_auc: 0.6494 - val_auc_1: 0.3267\n",
      "Epoch 195/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3862 - auc: 0.8046 - auc_1: 0.5153 - val_loss: 0.4791 - val_auc: 0.6458 - val_auc_1: 0.3222\n",
      "Epoch 196/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3862 - auc: 0.8046 - auc_1: 0.5159 - val_loss: 0.4780 - val_auc: 0.6486 - val_auc_1: 0.3231\n",
      "Epoch 197/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3860 - auc: 0.8049 - auc_1: 0.5157 - val_loss: 0.4798 - val_auc: 0.6493 - val_auc_1: 0.3285\n",
      "Epoch 198/200\n",
      "191/191 [==============================] - 28s 142ms/step - loss: 0.3859 - auc: 0.8049 - auc_1: 0.5159 - val_loss: 0.4809 - val_auc: 0.6451 - val_auc_1: 0.3280\n",
      "Epoch 199/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3859 - auc: 0.8049 - auc_1: 0.5161 - val_loss: 0.4805 - val_auc: 0.6490 - val_auc_1: 0.3278\n",
      "Epoch 200/200\n",
      "191/191 [==============================] - 28s 143ms/step - loss: 0.3858 - auc: 0.8051 - auc_1: 0.5164 - val_loss: 0.4779 - val_auc: 0.6487 - val_auc_1: 0.3236\n"
     ]
    }
   ],
   "source": [
    "call_train(process_file,200,32,path+'/output',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbasset_env",
   "language": "python",
   "name": "scbasset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
